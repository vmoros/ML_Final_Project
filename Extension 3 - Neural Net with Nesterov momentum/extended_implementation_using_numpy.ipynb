{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Homemade implementations of Extension 3 - Neural Net with Nesterov momentum</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import numpy.random as r\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X_all = digits.data\n",
    "X_all = StandardScaler().fit_transform(X_all)\n",
    "y_all = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, train_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y_to_vect(y):\n",
    "    y_vect = np.zeros((len(y), 10))\n",
    "    for i in range(len(y)):\n",
    "        y_vect[i, y[i]] = 1\n",
    "    return y_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_v_train = convert_y_to_vect(y_train)\n",
    "y_v_test = convert_y_to_vect(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the spam data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table('SMSSpamCollection', sep = '\\t', header=None, names=['label', 'sms_message'])\n",
    "df['label']=df.label.map({'spam':1, 'ham':0})\n",
    "df_train_msgs, df_test_msgs, df_ytrain, df_ytest = train_test_split(df['sms_message'],df['label'], random_state=0)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(binary = True, stop_words='english')\n",
    "vectorizer.fit(df_train_msgs)\n",
    "X_train_msgs = vectorizer.transform(df_train_msgs).toarray()\n",
    "X_test_msgs = vectorizer.transform(df_test_msgs).toarray()\n",
    "y_train_msgs = df_ytrain.to_numpy()\n",
    "y_test_msgs = df_ytest.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y_to_vect_spam(y):\n",
    "    y_vect = np.zeros((len(y), 2))\n",
    "    for i in range(len(y)):\n",
    "        y_vect[i, y[i]] = 1\n",
    "    return y_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_v_train_msgs = convert_y_to_vect_spam(y_train_msgs)\n",
    "y_v_test_msgs = convert_y_to_vect_spam(y_test_msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(z):\n",
    "    return np.tanh(z)\n",
    "\n",
    "def tanh_deriv(z):\n",
    "    return 1 - np.square(tanh(z))\n",
    "\n",
    "def setup_and_init_weights(nn_structure):\n",
    "    W = {} #creating a dictionary i.e. a set of key: value pairs\n",
    "    b = {}\n",
    "    prev_vel_w = {}\n",
    "    vel_w = {}\n",
    "    prev_vel_b = {}\n",
    "    vel_b = {}\n",
    "    for l in range(1, len(nn_structure)):\n",
    "        xavier_range = 4 * np.sqrt(6 / (nn_structure[l] + nn_structure[l-1]))\n",
    "        W[l] = r.uniform(-xavier_range, xavier_range, (nn_structure[l], nn_structure[l-1]))\n",
    "        b[l] = r.random_sample((nn_structure[l],))\n",
    "        prev_vel_w[l] = vel_w[l] = np.zeros((nn_structure[l], nn_structure[l-1]))\n",
    "        vel_w[l] = np.zeros((nn_structure[l], nn_structure[l-1]))\n",
    "        prev_vel_b[l] = np.zeros((nn_structure[l],))\n",
    "        vel_b[l] = np.zeros((nn_structure[l],))\n",
    "        \n",
    "        \n",
    "    return W, b, prev_vel_w, vel_w, prev_vel_b, vel_b\n",
    "\n",
    "def init_tri_values(nn_structure):\n",
    "    tri_W = {}\n",
    "    tri_b = {}\n",
    "    for l in range(1, len(nn_structure)):\n",
    "        tri_W[l] = np.zeros((nn_structure[l], nn_structure[l-1]))\n",
    "        tri_b[l] = np.zeros((nn_structure[l],))\n",
    "    return tri_W, tri_b\n",
    "\n",
    "def feed_forward(x, W, b):\n",
    "    a = {1: x} # create a dictionary for holding the a values for all levels\n",
    "    z = { } # create a dictionary for holding the z values for all the layers\n",
    "    for l in range(1, len(W) + 1): # for each layer\n",
    "        node_in = a[l]\n",
    "        z[l+1] = W[l].dot(node_in) + b[l]  # z^(l+1) = W^(l)*a^(l) + b^(l)\n",
    "        a[l+1] = tanh(z[l+1]) # a^(l+1) = f(z^(l+1))\n",
    "    return a, z\n",
    "\n",
    "def calculate_out_layer_delta(y, a_out, z_out):\n",
    "    return -(y-a_out) * tanh_deriv(z_out) \n",
    "\n",
    "def calculate_hidden_delta(delta_plus_1, w_l, z_l):\n",
    "    return np.dot(np.transpose(w_l), delta_plus_1) * tanh_deriv(z_l)\n",
    "\n",
    "def predict_y(W, b, X, n_layers):\n",
    "    N = X.shape[0]\n",
    "    y = np.zeros((N,))\n",
    "    for i in range(N):\n",
    "        a, z = feed_forward(X[i, :], W, b)\n",
    "        y[i] = np.argmax(a[n_layers])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_structure = [64, 30, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(nn_structure, X, y, iter_num=3000, alpha=0.25, lamb=0, momentum=False):\n",
    "    W, b, prev_vel_w, vel_w, prev_vel_b, vel_b = setup_and_init_weights(nn_structure)\n",
    "    N = len(y)\n",
    "    for i in range(iter_num):\n",
    "        tri_W, tri_b = init_tri_values(nn_structure)\n",
    "        for i in range(N):\n",
    "            delta = {}\n",
    "            a, z = feed_forward(X[i, :], W, b)\n",
    "            for l in range(len(nn_structure), 0, -1):\n",
    "                if l == len(nn_structure):\n",
    "                    delta[l] = calculate_out_layer_delta(y[i,:], a[l], z[l])\n",
    "                else:\n",
    "                    if l > 1:\n",
    "                        delta[l] = calculate_hidden_delta(delta[l+1], W[l], z[l])\n",
    "                    tri_W[l] += np.dot(delta[l+1][:,np.newaxis], np.transpose(a[l][:,np.newaxis]))# np.newaxis increase the number of dimensions\n",
    "                    tri_b[l] += delta[l+1]\n",
    "\n",
    "        for l in range(len(nn_structure) - 1, 0, -1):\n",
    "            grad_w = 1.0/N * tri_W[l] + lamb * W[l]\n",
    "            grad_b = 1.0/N * tri_b[l]\n",
    "            if momentum:\n",
    "                prev_vel_w[l] = vel_w[l]\n",
    "                vel_w[l] = 0.9 * vel_w[l] - alpha * grad_w\n",
    "                W[l] += -0.9 * prev_vel_w[l] + 1.9 * vel_w[l]\n",
    "                \n",
    "                prev_vel_b[l] = vel_b[l]\n",
    "                vel_b[l] = 0.9 * vel_b[l] - alpha * grad_b\n",
    "                b[l] += -0.9 * prev_vel_b[l] + 1.9 * vel_b[l]\n",
    "            else:\n",
    "                W[l] += -alpha * grad_w\n",
    "                b[l] += -alpha * grad_b\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate my homemade implementation's accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Check the accuracy of my neural network with Nesterov momentum on the digits data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of my implementation of NN with Nesterov momentum on the digits data is 97.5%\n"
     ]
    }
   ],
   "source": [
    "mome_w, mome_b = train_nn(nn_structure, X_train, y_v_train, iter_num=3000, alpha=0.1, lamb=0.001, momentum=True)\n",
    "mome_y_pred = predict_y(mome_w, mome_b, X_test, 3)\n",
    "print(f\"The accuracy of my implementation of NN with Nesterov momentum on the digits data is {100 * accuracy_score(y_test, mome_y_pred)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Check the accuracy of my neural network with Nesterov momentum on the spam data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_structure_spam = [X_train_msgs.shape[1], 30, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of my implementation of NN with Nesterov momentum is 98.27709978463747%\n"
     ]
    }
   ],
   "source": [
    "mome_w_spam, mome_b_spam = train_nn(nn_structure_spam, X_train_msgs, y_v_train_msgs, iter_num=100, alpha=0.1, lamb=0.001, momentum=True)\n",
    "mome_y_pred_spam = predict_y(mome_w_spam, mome_b_spam, X_test_msgs, 3)\n",
    "print(f\"The accuracy of my implementation of NN with Nesterov momentum is {100 * accuracy_score(y_test_msgs, mome_y_pred_spam)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
